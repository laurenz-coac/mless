{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29fe2d4d",
      "metadata": {
        "id": "29fe2d4d"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenz-coac/mless/blob/main/homework2/5_LSTM_ozone_future.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92e6157c",
      "metadata": {
        "id": "92e6157c"
      },
      "source": [
        "# The Approaches:\n",
        "\n",
        "If we want to incorporate future temperature data to predict current ozone measurements, we have two approaches that do not require architectural changes:\n",
        "\n",
        "1. **Shifting the temperature measurements backwards:** Say our context window starts at $t=0$ and goes until timepoint $t=w_c$. Our prediciton window then, of course, starts at $t=w_c +1$ and goes until $t=w_c + w_p$, where $w_p$ is the length of the prediciton window. In this case (if we have two input variables), the input dimensions to our model are $(N, w_c, 2)$. To include future data for the temperature variable, we can shift the temperature data by $k$ timepoints, s.t. the first measurement included in the context window would be from timepoint $t=k$, while the last timepoint would be at $t=w_c + k$. This way, the model can see $k$ steps into the future, at the cost of losing the first $k$ measurements for the temperature data.\n",
        "\n",
        "2. **Appending and Padding:** If we do not want to lose the information at the beginning of the temperature sequence, we can also append the whole future window for this variable to our context window. Then the data would be of dimensionality $(N, w_c + w_p, 2)$, where the last $w_p$ indices for ozone would be some padding value (probably best to pick an out-of-distribution value). If the model struggles with the large sequence of pads, the task could also be reformulated to a single-step prediciton task.\n",
        "\n",
        "(**A probably better apporach:** If we can make architectural changes, it would probably be a good idea to revert to an encoder-decoder architecture, where the _past_ data is encoded together, and future temperature data is only given to the decoder while predicting ozone values. In this way, we have an explicit distinction between past and future values, which can probably be learned more efficiently by the model.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "46be3f8f",
      "metadata": {
        "id": "46be3f8f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "context_window = 336\n",
        "prediction_horizon = 96\n",
        "variable_column = [\"temp\", \"o3\"] # define the variables wanted for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c28ae27c",
      "metadata": {
        "id": "c28ae27c"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CguAzHMVBBdE",
      "metadata": {
        "id": "CguAzHMVBBdE"
      },
      "source": [
        "# Loading multi-variable data-sequence\n",
        "\n",
        "Here the same as in the original ozone-prediction notebook is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1dac2884",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dac2884",
        "outputId": "ed21fbea-f382-4885-842a-a5f8d3c32123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_full shape: (21493, 336, 3), y_train_full shape: (21493, 96, 3)\n",
            "X_test_full shape: (9212, 336, 3), y_test_full shape: (9212, 96, 3)\n",
            "X_train shape: (21493, 336, 2), y_train shape: (21493, 96)\n",
            "X_test shape: (9212, 336, 2), y_test shape: (9212, 96)\n"
          ]
        }
      ],
      "source": [
        "from re import X\n",
        "import pickle\n",
        "\n",
        "# Load the prepared multi-variable data\n",
        "with open(\"X_train.pkl\", \"rb\") as f:\n",
        "    X_train_full = pickle.load(f)\n",
        "\n",
        "with open(\"X_test.pkl\", \"rb\") as f:\n",
        "    X_test_full = pickle.load(f)\n",
        "\n",
        "with open(\"y_train.pkl\", \"rb\") as f:\n",
        "    y_train_full = pickle.load(f)\n",
        "\n",
        "with open(\"y_test.pkl\", \"rb\") as f:\n",
        "    y_test_full = pickle.load(f)\n",
        "\n",
        "print(f\"X_train_full shape: {X_train_full.shape}, y_train_full shape: {y_train_full.shape}\")\n",
        "print(f\"X_test_full shape: {X_test_full.shape}, y_test_full shape: {y_test_full.shape}\")\n",
        "\n",
        "## Else if using local files:\n",
        "dataframe = pd.read_csv(\"normalized_data.csv\")\n",
        "scaler_stats = {col: {'mean': dataframe[col].mean(), 'std': dataframe[col].std()} for col in variable_column}\n",
        "\n",
        "\n",
        "# the station code is the first variable column, hence select only the last two\n",
        "X_train = X_train_full[:,:,1:].copy()\n",
        "X_test = X_test_full[:,:,1:].copy()\n",
        "\n",
        "# for the label, we only want the ozone data, which is the second column\n",
        "\n",
        "temp_y_train = y_train_full[:,:,1].copy()  # temperature data for training\n",
        "temp_y_test = y_test_full[:,:,1].copy()    # temperature data for testing\n",
        "\n",
        "y_train = y_train_full[:,:,2].copy()\n",
        "y_test = y_test_full[:,:,2].copy()\n",
        "\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "X_test = np.array(X_test, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "y_test = np.array(y_test, dtype=np.float32)\n",
        "temp_y_train = np.array(temp_y_train, dtype=np.float32)\n",
        "temp_y_test = np.array(temp_y_test, dtype=np.float32)\n",
        "\n",
        "# verify the shapes of the data\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125bf7d7",
      "metadata": {
        "id": "125bf7d7"
      },
      "source": [
        "## Define Training Function\n",
        "\n",
        "The model is trained in the same way for both approaches, only the data preparation is different. The only thing we need to account for is the context-window length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "92c3c60a",
      "metadata": {
        "id": "92c3c60a"
      },
      "outputs": [],
      "source": [
        "def train_lstm_model(X_train, y_train, context_window):\n",
        "\n",
        "    # Tunable LSTM parameters\n",
        "    lstm_units = 50\n",
        "    lstm_epochs = 5\n",
        "    lstm_batch_size = 16\n",
        "    lstm_optim = 'adam'\n",
        "    lstm_loss = 'mse'\n",
        "\n",
        "    checkpoint_dir = \"./checkpoint/\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"lstm_multivar.h5\")\n",
        "\n",
        "    ## Ignore user warning on keras as the choice for this exercise is to use h5.\n",
        "    print(f\"Training new model for variables {variable_column}\")\n",
        "\n",
        "    # the only change needed to allow for multiple input variables is to change the input shape of the LSTM layer\n",
        "    # to match the number of variables in the input data\n",
        "    lstm_model = Sequential([\n",
        "        LSTM(lstm_units, return_sequences=True, input_shape=(context_window, len(variable_column))), # change to allow mulitple input variables\n",
        "        LSTM(lstm_units, return_sequences=False),\n",
        "        Dense(prediction_horizon)\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        checkpoint_path, monitor=\"val_loss\", save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    training = lstm_model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=lstm_epochs, batch_size=lstm_batch_size,\n",
        "        validation_split=0.2, verbose=1,\n",
        "        callbacks=[checkpoint_callback]\n",
        "    )\n",
        "\n",
        "    training_history = training.history\n",
        "\n",
        "    return lstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7c0b0ac2",
      "metadata": {
        "id": "7c0b0ac2"
      },
      "outputs": [],
      "source": [
        "def get_ozone_predictions(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Get ozone predictions from the trained model.\n",
        "    \"\"\"\n",
        "    lstm_pred = model.predict(X_test)\n",
        "    rmse = evaluate_model(y_test, lstm_pred)\n",
        "\n",
        "    return lstm_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions(lstm_pred, filename):\n",
        "\n",
        "  X_first_idx = np.flatnonzero(X_test_full[:, 0, 0] == 'DENW094')[0]\n",
        "  context=X_test_full[X_first_idx, :, 2] # for comparability, stick with given code, even though not necessary\n",
        "  # First sample of DENW094 station to compare with PatchTST\n",
        "\n",
        "  actual_future = y_test[X_first_idx, :]\n",
        "  predicted_future = lstm_pred[X_first_idx, :] #actual and pred denormalized in prev cell\n",
        "\n",
        "  # Inverse scale\n",
        "  predicted_future = predicted_future * scaler_stats[variable_column[1]]['std'] + scaler_stats[variable_column[1]]['mean']\n",
        "\n",
        "  #write forecast values to csv\n",
        "  forecast_df = pd.DataFrame({\n",
        "      'timepoints': range(context_window, context_window + prediction_horizon),\n",
        "      'forecast': predicted_future\n",
        "  })\n",
        "\n",
        "  forecast_df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "U5qmOkE9Afoy"
      },
      "id": "U5qmOkE9Afoy",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6744cb5a",
      "metadata": {
        "id": "6744cb5a"
      },
      "source": [
        "# Approach 1\n",
        "\n",
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "271b11b0",
      "metadata": {
        "id": "271b11b0"
      },
      "outputs": [],
      "source": [
        "k = 96 # shift the temp data by k hours to use future temperature data\n",
        "# play around with k to see impact\n",
        "\n",
        "temp_train = X_train[:, k:, 0].copy() # take the temperature data from the training set\n",
        "temp_future = temp_y_train[:, :k].copy() # take the temperature data from the future set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_train.shape, temp_future.shape"
      ],
      "metadata": {
        "id": "AJK_N2Os7AEm",
        "outputId": "637cad2d-a854-4380-f140-56d9a25d8877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AJK_N2Os7AEm",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21493, 240), (21493, 96))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "865e3c37",
      "metadata": {
        "id": "865e3c37"
      },
      "outputs": [],
      "source": [
        "concat_temp = np.concatenate((temp_train, temp_future), axis=1) # concatenate the two temperature data sets\n",
        "\n",
        "# replace temperature data in the training set with the concatenated data\n",
        "X_train1 = X_train.copy()  # create a copy of the training data to avoid modifying the original\n",
        "X_train1[:, :, 0] = concat_temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the LSTM model with the modified training data\n",
        "lstm_model = train_lstm_model(X_train1, y_train, context_window)"
      ],
      "metadata": {
        "id": "q-VUXS8l7LFn",
        "outputId": "e908140f-270f-450e-8721-4e619e7df457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q-VUXS8l7LFn",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training new model for variables ['temp', 'o3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1073/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6623\n",
            "Epoch 1: val_loss improved from inf to 0.62365, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.6620 - val_loss: 0.6237\n",
            "Epoch 2/5\n",
            "\u001b[1m1073/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4449\n",
            "Epoch 2: val_loss improved from 0.62365 to 0.54300, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - loss: 0.4449 - val_loss: 0.5430\n",
            "Epoch 3/5\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4223\n",
            "Epoch 3: val_loss improved from 0.54300 to 0.49731, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - loss: 0.4223 - val_loss: 0.4973\n",
            "Epoch 4/5\n",
            "\u001b[1m1073/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3475\n",
            "Epoch 4: val_loss did not improve from 0.49731\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - loss: 0.3475 - val_loss: 0.5217\n",
            "Epoch 5/5\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3484\n",
            "Epoch 5: val_loss did not improve from 0.49731\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - loss: 0.3484 - val_loss: 0.5113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare test data in the same way\n",
        "\n",
        "temp_test = X_test[:, k:, 0].copy() # take the temperature data from the test set\n",
        "temp_future = temp_y_test[:, :k].copy() # take the temperature data from the future set\n",
        "\n",
        "concat_temp = np.concatenate((temp_test, temp_future), axis=1) # concatenate the two temperature data sets\n",
        "\n",
        "# replace temperature data in the test set with the concatenated data\n",
        "X_test1 = X_test.copy()  # create a copy of the test data to avoid modifying the original\n",
        "X_test1[:, :, 0] = concat_temp"
      ],
      "metadata": {
        "id": "Hs148DrP70ae"
      },
      "id": "Hs148DrP70ae",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_pred = get_ozone_predictions(lstm_model, X_test1, y_test)"
      ],
      "metadata": {
        "id": "jocu6SXI7sL_",
        "outputId": "d5a9f5ea-62b6-4ffd-d8ea-52b81a17ebd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jocu6SXI7sL_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "RMSE: 0.6740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_predictions(lstm_pred, \"LSTM_futureA1_forecast_k96.csv\")"
      ],
      "metadata": {
        "id": "KPBdCLURBSZm"
      },
      "id": "KPBdCLURBSZm",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "61fd53e9",
      "metadata": {
        "id": "61fd53e9"
      },
      "source": [
        "# Approach 2\n",
        "\n",
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c155ccfe",
      "metadata": {
        "id": "c155ccfe"
      },
      "outputs": [],
      "source": [
        "y_train_vars = y_train_full[:, :, 1:]\n",
        "\n",
        "X_train2 = np.concatenate((X_train, y_train_vars), axis=1)  # concatenate the training data with the test data\n",
        "\n",
        "# mask out the ozone data in the training set\n",
        "X_train2[:, context_window:, 1] = -99\n",
        "X_train2 = np.array(X_train2, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2.shape"
      ],
      "metadata": {
        "id": "4TintByn964P",
        "outputId": "2b223b86-afed-4aa6-8b39-003f7f7e2005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4TintByn964P",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21493, 432, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the LSTM model with the modified training data\n",
        "lstm_model = train_lstm_model(X_train2, y_train, X_train2.shape[1])"
      ],
      "metadata": {
        "id": "bXj_woHK-HkG",
        "outputId": "60ca4330-e373-471a-974e-7ee437992b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bXj_woHK-HkG",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training new model for variables ['temp', 'o3']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1074/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.7411\n",
            "Epoch 1: val_loss improved from inf to 0.56473, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 31ms/step - loss: 0.7408 - val_loss: 0.5647\n",
            "Epoch 2/5\n",
            "\u001b[1m1073/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4875\n",
            "Epoch 2: val_loss improved from 0.56473 to 0.55644, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 30ms/step - loss: 0.4875 - val_loss: 0.5564\n",
            "Epoch 3/5\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4385\n",
            "Epoch 3: val_loss improved from 0.55644 to 0.53643, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.4385 - val_loss: 0.5364\n",
            "Epoch 4/5\n",
            "\u001b[1m1074/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4040\n",
            "Epoch 4: val_loss improved from 0.53643 to 0.51672, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 30ms/step - loss: 0.4040 - val_loss: 0.5167\n",
            "Epoch 5/5\n",
            "\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3753\n",
            "Epoch 5: val_loss improved from 0.51672 to 0.50961, saving model to ./checkpoint/lstm_multivar.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1075/1075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 31ms/step - loss: 0.3753 - val_loss: 0.5096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the test data in the same way\n",
        "\n",
        "y_test_vars = y_test_full[:, :, 1:]\n",
        "\n",
        "X_test2 = np.concatenate((X_test, y_test_vars), axis=1)  # concatenate\n",
        "X_test2[:, context_window:, 1] = -99\n",
        "X_test2 = np.array(X_test2, dtype=np.float32)\n",
        "\n",
        "lstm_pred = get_ozone_predictions(lstm_model, X_test2, y_test)"
      ],
      "metadata": {
        "id": "Z89PucEm_Vrv",
        "outputId": "a11973c3-72fc-48ab-e5fc-bf9d271697ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z89PucEm_Vrv",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "RMSE: 0.6370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_predictions(lstm_pred, \"LSTM_futureA2_forecast.csv\")"
      ],
      "metadata": {
        "id": "pEnJMpbR_1NC"
      },
      "id": "pEnJMpbR_1NC",
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}